# Training Configuration for Hive Personality Model
# This file defines all hyperparameters and settings for fine-tuning

model:
  # Base model to fine-tune (you can change this to any compatible model)
  base_model: "unsloth/Llama-3.2-3B-Instruct"  # Fast, efficient 3B model
  # Alternative options:
  # - "unsloth/Qwen2.5-3B-Instruct"
  # - "unsloth/Phi-4"
  # - "unsloth/Mistral-7B-Instruct-v0.3"
  
  # Model configuration
  max_seq_length: 2048
  load_in_4bit: true  # Use 4-bit quantization for memory efficiency
  
dataset:
  # Path to your personality dataset
  train_file: "dataset/final/personality.jsonl"
  # Train/validation split ratio
  validation_split: 0.05
  # Maximum samples to use (null = use all)
  max_samples: null

lora:
  # LoRA (Low-Rank Adaptation) settings
  r: 16  # LoRA rank (higher = more parameters, better quality but slower)
  lora_alpha: 16  # LoRA scaling factor
  lora_dropout: 0.05
  # Target modules for LoRA adaptation
  target_modules:
    - q_proj
    - k_proj
    - v_proj
    - o_proj
    - gate_proj
    - up_proj
    - down_proj
  bias: "none"
  task_type: "CAUSAL_LM"

training:
  # Training hyperparameters
  output_dir: "outputs"
  num_train_epochs: 3
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 4  # Effective batch size = 2 * 4 = 8
  
  # Optimizer settings
  optim: "adamw_8bit"  # Memory-efficient optimizer
  learning_rate: 2.0e-4
  weight_decay: 0.01
  warmup_steps: 5
  
  # Training efficiency
  fp16: false
  bf16: true  # Use bfloat16 for better numerical stability
  max_grad_norm: 0.3
  
  # Logging and saving
  logging_steps: 10
  save_strategy: "steps"
  save_steps: 100
  save_total_limit: 2
  
  # Evaluation
  evaluation_strategy: "steps"
  eval_steps: 100
  
  # Misc
  group_by_length: true  # Group sequences by length for efficiency
  report_to: "none"  # Options: "wandb", "tensorboard", "none"
  seed: 42

generation:
  # Settings for text generation during evaluation
  max_new_tokens: 128
  temperature: 0.7
  top_p: 0.9
  do_sample: true

export:
  # Export settings after training
  save_method: "merged_16bit"  # Options: "lora", "merged_16bit", "merged_4bit", "gguf"
  quantization_method: "q4_k_m"  # For GGUF export
  output_name: "hive-personality"
