# ğŸ Hive Wiki â€” Home

Welcome to the Hive wiki. You found the documentation that lives behind the documentation. Very meta.

**Hive** is a WhatsApp-to-LLM personality fine-tuning pipeline. You give it your chats. It gives back a dataset. You train a model. You now have a language model that talks like you. The existential implications are your problem.

---

## ğŸ“š Wiki Pages

| Page | What it covers |
|------|----------------|
| [Architecture](Architecture) | How the pipeline is structured, what each script does, LoRA explained like you're five |
| [Installation](Installation) | Getting the thing running â€” local, Kaggle, Colab, RunPod |
| [Usage](Usage) | The full pipeline walkthrough from chat export to model export |
| [Privacy](Privacy) | What data goes where, what to do before going public |
| [Troubleshooting](Troubleshooting) | When things go sideways (and they will) |
| [Roadmap](Roadmap) | What's coming next, what's being considered, what's a pipe dream |
| [DataSpecs](DataSpecs) | JSONL format, input format, filtering rules |

---

## âš¡ Quick Start (TL;DR)

```bash
# 1. Set YOUR_NAME in extract.py
# 2. Drop WhatsApp .txt exports in dataset/raw/
# 3. Run the pipeline:
python extract.py
python convert.py
python validate_dataset.py
python train.py
python export_model.py --input outputs/final_model --type gguf
```

That's it. Your personality is now a `.gguf` file.

---

## ğŸ—ï¸ What This Actually Does

```
WhatsApp .txt
     â”‚
     â–¼ extract.py
dataset/cleaned/   â† just your messages, cleaned
     â”‚
     â–¼ convert.py
dataset/final/personality.jsonl  â† 21,009 conv pairs
     â”‚
     â–¼ train.py  (Unsloth + LoRA + 4-bit QLoRA)
outputs/final_model/
     â”‚
     â–¼ export_model.py
exports/hive-personality.gguf  â† run in Ollama
```

---

*Enjoy the memes. Take the privacy section seriously. ğŸ*